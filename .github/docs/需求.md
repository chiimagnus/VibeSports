## 1、项目定位（vibe-sports）

做一个 macOS 原生「摄像头跑步游戏」（Webcam Runner）复刻：用户主动点击开始后，App 采集摄像头画面，用 Apple Vision 提取人体姿态关键点，估计原地跑步的运动强度，并驱动一个 3D 无限场景“向前奔跑”。

重要约束（已确认）：

- 不做自动提醒、不做前台 App 检测
- 不做“不可跳过/强制完成”流程
- 不使用 Three.js / MediaPipe（完全原生：SwiftUI + Apple Vision + 原生 3D）
- 先实现 Phase B（3D 无限场景 + 跑步检测），Phase C（AI 陪跑）下一阶段再做

## 2、参考资源

- Web 版参考（目标对齐）：https://github.com/Jamesun921/cam-run
- Apple 示例（姿态/计数思路参考）：https://developer.apple.com/documentation/CreateMLComponents/counting-human-body-action-repetitions-in-a-live-video-feed

## 3、需求分析

### 摄像头视角与可见范围

笔记本/iMac 摄像头在屏幕顶部，用户站在桌前时：

| 距离 | 大概能看到 | 对检测的影响 |
| --- | --- | --- |
| **贴着桌子** | 头 + 肩 + 部分胸 | 适合“近距离模式”（上肢摆臂/节律） |
| **退后半步（~0.5m）** | 头到腰 | 上肢/躯干可靠，下肢不稳定 |
| **退后一步（~1m）** | 全身或大半身 | 适合“标准模式”（下肢步频/节律） |

### 运动指标（对标 cam-run-master）

- `movementQuality`：运动质量/置信度（0~100）
- `speed`：速度（映射/平滑后用于驱动场景推进）
- `steps`：步数（由步频/摆臂相位变化推导）
- `calories`：热量（按 MET + 体重 + 时间估算）
- `weight`：体重（用户可编辑，影响热量估算）

## 4、需求理解确认（Phase B）

### 交互流程

1. App 启动：展示说明 + 体重设置 + 「开始运动」
2. 点击开始：请求摄像头权限 → 进入跑步会话
3. 会话中：3D 场景持续渲染，摄像头姿态检测驱动速度/步数/热量
4. 点击结束：停止检测与摄像头，回到起始页

### 运动检测

- 技术：Apple Vision（人体姿态关键点）
- 标准模式：下肢关键点可见时，优先用膝/踝节律推导步频
- 近距离模式：下肢不可见但上肢可见时，用摆臂节律推导步频（对标 cam-run 的 close-up 思路）

### 3D 场景

- 原生 3D（优先 SceneKit + `SCNView` 嵌入 SwiftUI）
- 无限地形：固定数量地形段循环复用 + 装饰物池化，避免节点无限增长
- 相机动画：随速度轻微抖动/高度变化，增强速度反馈

## 5、Non-goals

- Phase C：AI 陪跑（实时动作指导/个性化反馈/自适应难度）
- 任何自动提醒/强制完成机制
- 运动历史、多端同步、Apple Watch
